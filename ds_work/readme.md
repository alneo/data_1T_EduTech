# 1. Обучение моделей прогнозирования результативности завершения учебных курсов пользователями

В файле [zloy/project_2911/m2_and_success_prediction.ipynb](./ipynbs/m2_and_success_prediction.ipynb) [m2_and_success_prediction.py](./ipynbs/m2_and_success_prediction.py) представлен код обучения моделей прогнозирования результативности завершения учебных курсов пользователями образовательной платформы.

Для обучения моделей использованы датасеты:
* `20241125_sprint.csv`
* `20241128_new_data.csv` 

объединенные в единый датафрейм. 

В целях корректной конкатенации двух таблиц поля датасета `20241128_new_data.csv` приведены к прежнему формату - к виду датасета  `20241125_sprint.csv`:
* `real_course_progress` - **m2_progress**, 
* `course_success` - **m2_success**.

Для определения лучшей модели проводится экспериментальное обучение и исследование моделей прогнозирования прогресса по курсу:
1. Линейная регрессия
2. Дерево решений
3. Случайный лес
4. Градиентный бустинг библиотеки scikit-learn
5. XGBoost
6. CatBoost
7. LightGBM

Поскольку прогресс по курсу представляет собой числовое значение от 0 до 100, модели решают задачу **регрессии**.

Особенность обучения моделей: 
* обучающие и валидационные выборки разбиты на 10 отдельных датасетов, 
* каждый из которых содержит данные по результатам соответствующей недели обучения. 
* В датасетах на ранних неделях данные за последующие недели заменены нулями, что позволяет исключить "подглядывание" модели в будущее и обеспечить чистоту эксперимента.
* Таким образом, обучено по 10 экземпляров каждого выбранного класса моделей (итого 70).

Оценка качества моделей осуществлялась по метрике `MAE` (Mean Absolute Error). Выбор метрики обусловлен её интерпретируемостью при прогнозировании прогресса от 0 до 100 (фактически приравнивается к процентной погрешности в +- от ожидаемого результата), а также сравнительной нечувствительностью к выбросам.

Кроме указанных моделей ранее тестировались **нейронные сети** (полносвязная и TabNet), однако, они продемонстрировали плохие результаты и были исключены из дальнейших экспериментов.

По результатам тестирования наилучшие показатели `MAE` продемонстрировали модели **случайного леса**, которые были сериализованы в файлы `rf_model_week_1.joblib`, `rf_model_week_2.joblib`, ... , `rf_model_week_10.joblib` [saved_models/project_2911/](saved_models/project_2911/).

Обучение моделей прогнозирования вероятности успешного окончания курса проводилось по аналогичному сценарию, с особенностями:
- решается бинарной классификации (**0** - не окончил, **1** - окончил успешно);
- расчёт вероятности успешного окончания курса в диапазоне значений от 0 до 1 осуществляется посредством применения метода `predict_proba`.

В результате проведённого ранее эксперимента (исследование представлено в файле [zloy/project_2411_clf/success_prediction.ipynb](./ipynbs/success_prediction.ipynb)  [zloy/project_2411_clf/success_prediction.py](./ipynbs/success_prediction.py)  лучшие показатели продемонстрировали модели градиентного бустинга. 

Эти модели обучены (файл [zloy/project_2911/m2_and_success_prediction.ipynb](./ipynbs/m2_and_success_prediction.ipynb) [m2_and_success_prediction.py](./ipynbs/m2_and_success_prediction.py)) на тех же выборках, что и модели прогнозирования прогресса по курс, и сериализованы в файлы `zloy/project_2911/saved_clf_models/gb_model_week_1.joblib`, `gb_model_week_2.joblib`, ... , `gb_model_week_10.joblib` [saved_models/project_2911/](saved_models/project_2911/).

## Код использования обученных моделей

* [saved_models_test.ipynb](./ipynbs/saved_models_test.ipynb) [saved_models_test.py](./ipynbs/saved_models_test.py) - прогнозирование прогресса по курсу
[saved_clf_models_test.ipynb](./ipynbs/saved_clf_models_test.ipynb)
* [saved_clf_models_test.py](./ipynbs/saved_clf_models_test.py) - прогнозирование вероятности успешного завершения

# 2. Сборка сводного обзорного датасета (Инга)

[inga_overview.ipynb](./ipynbs/inga_overview.ipynb) [inga_overview.py](./ipynbs/inga_overview.py) сборка сводного обзорного датасета из файлов csv заказчика.

Результатом работы скрипта является наглядная таблица типа "1 студент - 1 строка" с различными суммарными показателями по курсу. 

Многие показатели в текущей работе не были задействованы, т.к. по детским курсам данные были неполные, но по взрослым картина другая. 

Для кураторов эта таблица может быть полезна, и расчёт суммарного времени просмотра вебинаров пригодится в будущем.

## Значения колонок

* `user_id` - идентификационный номер студента
* `course_id` - идентификационный номер курса
* `course_progress`	- прогресс по курсу, %
* `course_attestation` - аттестация (значение в % / не сдана)
* `course_attestation_date` - дата аттестации
* `first_authirization` - дата первой авторизации
* `num_of_auth`	- общее количество авторизаций
* `webinar_int` - просмотр водного вебинара (да/нет)
* `w_view_hours` - общее количество часов просмотра вебинаров
* `view_task_id` - общее количество просмотренных заданий
* `view_activity_id` - общее количество просмотренных активностей
* `required_task` - общее количество выполненных обязательных неаттестационных активностей
* `optional_task` - общее количество выполненных необязательных неаттестационных активностей
* `attestation_task` - общее количество выполненных аттестационных активностей
* `result_mean`	- средний результат выполнения обязательных неаттестационных активностей, %
* `success_mean` - средний успех выполнения обязательных неаттестационных активностей (отношение удачных попыток выполнения ко всем попыткам) от 0 до 1
* `delay_days_mean`	- среднее количество дней, потребовавшихся на выполнение неаттестационных активностей
* `progress_calculated` - рассчетный прогресс по курсу, %

# Модели определяющие кластер на текущий момент времени и прогнозирующие вероятность успешного завершения курса

Подробнее смотри в [lubov](./lubov)